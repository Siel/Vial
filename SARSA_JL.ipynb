{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 install julia\n",
    "#import julia\n",
    "#julia.install()\n",
    "\n",
    "#Temporal fix because this python installation does not have libpython\n",
    "# from julia.api import Julia\n",
    "# jl = Julia(compiled_modules=False)\n",
    "#!pip3 install numpy\n",
    "# !pip3 install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from npodjlEnv import NpodJLEnv\n",
    "import numpy as np\n",
    "env = NpodJLEnv()\n",
    "env.ver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmaxQ(Q, s, n_actions):\n",
    "    if s in Q.keys():\n",
    "        print(\"Policy: Greedy\")\n",
    "        return(np.argmax(Q[s]))\n",
    "    else:\n",
    "        print(\"Policy: Random\")\n",
    "        return(np.random.randint(0, n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_greedy(Q, s, epsilon, n_actions):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return(argmaxQ(Q,s,n_actions))\n",
    "    else:\n",
    "        print(\"Policy: Random\")\n",
    "        return(np.random.randint(0, n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARSA(env, alpha, gamma, epsilon, Q, max_cylces):\n",
    "    n_actions = len(env.actions())\n",
    "    r = [None] * (max_cycles+1)\n",
    "    s = [None] * (2*(max_cycles+1))\n",
    "    a = [None] * (2*max_cycles)\n",
    "    \n",
    "    t=0\n",
    "    s[t] = env.encoded_state()\n",
    "    a[t] = policy_greedy(Q,s[t], epsilon, n_actions)\n",
    "    obs = env.run(a[t])\n",
    "    r[t] = obs['reward']\n",
    "    s[t+1] = env.encoded_state() \n",
    "    if not s[t] in Q.keys():\n",
    "        Q[s[t]] = [0]*n_actions\n",
    "    try:\n",
    "        while t < max_cycles:\n",
    "            print(\"State: \",env.encoded_state())\n",
    "            a[t+1] = policy_greedy(Q,s[t+1], epsilon, n_actions)\n",
    "            print(\"Action: \", a[t])\n",
    "            obs = env.run(a[t])\n",
    "            print(\"Reward: \", obs['reward'])\n",
    "            print(\"-----\")\n",
    "            r[t+1] = obs['reward']\n",
    "            s[t+2] = env.encoded_state()\n",
    "            if not s[t+1] in Q.keys():\n",
    "                Q[s[t+1]] = [0]*n_actions\n",
    "            Q[s[t]][a[t]] = Q[s[t]][a[t]] + alpha * ( r[t] + (gamma * Q[s[t+1]][a[t+1]] ) - Q[s[t]][a[t]] )\n",
    "            t += 1\n",
    "        print(r)\n",
    "        print(\"Total Reward: \", sum(r))\n",
    "        return(sum(r))\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Press Ctrl-C to terminate while statement\")\n",
    "        pass\n",
    "    return(s,a,r,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "alpha = 1\n",
    "gamma = 0.99\n",
    "epsilon = 0.5\n",
    "max_cycles = 20\n",
    "#sol = SARSA(env, alpha, gamma, epsilon, Q, max_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward=[]\n",
    "for i in range(1,40):\n",
    "        print(i)\n",
    "        env.reset()\n",
    "        total_reward.append(SARSA(env, 0.9, 1, 1 - 1/i, Q, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
